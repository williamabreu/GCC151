{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise de Sentimentos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treinando a machine learning, utilizando o dataset recebido por email. (Faça o download e coloque a pasta dentro do repositorio)\n",
    "\n",
    "Este notebook faz o treinando de machine learning de um modelo de análise de sentimentos, utilizando o dataset do Buscapé fornecido (confidencial), de forma que:\n",
    "- Carrega e estrutura os dados do dataset em dicionário\n",
    "- Exibe estatísticas acerca da do dataset\n",
    "- Apresenta comentários acerca dos resultados obtidos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurações Iniciais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiramente, fazer o ajuste no path do Python para a raíz do projeto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processamento do Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregar a bliblioteca de normalização de texto e de dump de dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlputils.lexical.normalizer import Normalizer\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instanciar um objeto para fazer as normalizações necessárias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = Normalizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementar uma rotina de pré-processamento a ser aplicada em todo o dataset antes de construir o modelo e uma para auxiliar o carregamento dos dados, evitando replicação de código."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função ```preprocessing``` recebe um texto (string) de entrada e o deixa normalizado, conforme procedimentos de nível lexical, e retorna o próprio texto (string) mais compacto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text):\n",
    "    text = normalizer.to_lowercase(text)\n",
    "    text = normalizer.remove_ponctuations(text)\n",
    "    tokens = normalizer.tokenize_words(text)\n",
    "    tokens = normalizer.remove_stopwords(tokens)\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função ```all_files``` recebe o caminho do dataset a ser carregado e gera o caminho de todos os arquivos XML a serem lidos. O caminho de entrada deve terminal com ```/```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_files(dataset_path):\n",
    "    for directory in os.listdir(dataset_path):\n",
    "        if directory != '.DS_Store':\n",
    "            for stars in os.listdir(dataset_path + directory):\n",
    "                for file in os.listdir(dataset_path + directory + '/' + stars):\n",
    "                    if file.endswith('.xml'):\n",
    "                        yield '{}{}/{}/{}'.format(dataset_path, directory, stars, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função ```dumpvar``` salva em dados binário todo o valor de uma variável na memória. Basta fornecer o ponteiro do identificador da variável e o caminho onde será salvo o dump."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dumpvar(var, path):\n",
    "    path_itens = path.split('/')\n",
    "    path_dir = '/'.join(path_itens[:-1]) + '/'\n",
    "    \n",
    "    if not os.path.isdir(path_dir):\n",
    "        os.makedirs(path_dir)\n",
    "    \n",
    "    with open(path, 'wb') as fp:\n",
    "        pickle.dump(var, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função ```loadvar``` retorna o valor de uma dump de memória salvo em disco. Basta o caminho onde está salvo o dump e atribuir em uma variável."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadvar(path):\n",
    "    with open(path, 'rb') as fp:\n",
    "        return pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando o Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importar as bibliotecas utilizadas para fazer o parse do XML e criar a estrutura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xmltodict\n",
    "from xml.parsers.expat import ExpatError\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando os arquivos XML, exibindo estatísticas sobre eles e criando a estrutura que será utilizada no modelo de Machine Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "TEMPO DE EXECUÇÃO: 20.04 segundos\n",
      "Arquivos carregados OK: 67030\n",
      "Arquivos com ERRO: 0\n"
     ]
    }
   ],
   "source": [
    "dataset = {'polarity': [], 'pros': [], 'cons': [], 'review': []}\n",
    "count_ok = 0\n",
    "count_err = 0\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "for file in all_files('data/trainset/'):\n",
    "    filename = file.split('/')[-1]\n",
    "    with open(file, 'r') as text_file:\n",
    "        data = text_file.read()\n",
    "        try:\n",
    "            dict_data = xmltodict.parse(data)\n",
    "            polarity = float(dict_data['review']['stars']['@value'])\n",
    "            dataset['polarity'].append(int(polarity))\n",
    "            dataset['review'].append(str(dict_data['review']['opinion']))\n",
    "            dataset['pros'].append(str(dict_data['review']['pros']))\n",
    "            dataset['cons'].append(str(dict_data['review']['cons']))\n",
    "            count_ok += 1\n",
    "        except ExpatError:\n",
    "            print('Arquivo \"{}\" está com xml mal formatado'.format(file))\n",
    "            count_err += 1\n",
    "\n",
    "end_time = time.perf_counter()\n",
    "\n",
    "print('-------------------------------------------')\n",
    "print('TEMPO DE EXECUÇÃO: {:.2f} segundos'.format(end_time - start_time))\n",
    "print('Arquivos carregados OK:', count_ok)\n",
    "print('Arquivos com ERRO:', count_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estatísticas acerca do dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantidade de comentários:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67030\n"
     ]
    }
   ],
   "source": [
    "print(count_ok)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantidade de sentenças:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantidade de comentários por score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score #0: 671\n",
      "Score #1: 2396\n",
      "Score #2: 2892\n",
      "Score #3: 8937\n",
      "Score #4: 25778\n",
      "Score #5: 26356\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 6):\n",
    "    print('Score #{}: {}'.format(i, dataset['polarity'].count(i)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui, o dataset está sendo repartido ao meio para criar o conjunto de treinamento e o de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_test = count_ok // 2\n",
    "size_train = count_ok - size_test\n",
    "\n",
    "dataset['trainset'] = ['train'] * size_train + ['test'] * size_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cons</th>\n",
       "      <th>polarity</th>\n",
       "      <th>pros</th>\n",
       "      <th>review</th>\n",
       "      <th>trainset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Custo-Benefício\\nDurabilidade\\nQualidade do Ma...</td>\n",
       "      <td>3</td>\n",
       "      <td>Design</td>\n",
       "      <td>Se não fosse o uniforme do palmeiras seria uma...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Qualidade do Material\\nConforto</td>\n",
       "      <td>3</td>\n",
       "      <td>Design\\nCusto-Benefício</td>\n",
       "      <td>BBB\\n\\nO que gostei: GGG\\n\\nO que não gostei: ...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Durabilidade\\nQualidade do Material</td>\n",
       "      <td>3</td>\n",
       "      <td>Design\\nCusto-Benefício\\nConforto</td>\n",
       "      <td>Um bom produto por um preço de melhor ainda.\\n...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Design\\nCusto-Benefício\\nDurabilidade\\nQualida...</td>\n",
       "      <td>3</td>\n",
       "      <td>Não possui nenhum ponto positivo.</td>\n",
       "      <td>Essa camiseta do time esfecifico é muito boa p...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Custo-Benefício</td>\n",
       "      <td>3</td>\n",
       "      <td>Não possui nenhum ponto positivo.</td>\n",
       "      <td>NÃO TENHO MUiTO O QUE DiZER,AFiNAL COMPREi PAR...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                cons  polarity  \\\n",
       "0  Custo-Benefício\\nDurabilidade\\nQualidade do Ma...         3   \n",
       "1                    Qualidade do Material\\nConforto         3   \n",
       "2                Durabilidade\\nQualidade do Material         3   \n",
       "3  Design\\nCusto-Benefício\\nDurabilidade\\nQualida...         3   \n",
       "4                                    Custo-Benefício         3   \n",
       "\n",
       "                                pros  \\\n",
       "0                             Design   \n",
       "1            Design\\nCusto-Benefício   \n",
       "2  Design\\nCusto-Benefício\\nConforto   \n",
       "3  Não possui nenhum ponto positivo.   \n",
       "4  Não possui nenhum ponto positivo.   \n",
       "\n",
       "                                              review trainset  \n",
       "0  Se não fosse o uniforme do palmeiras seria uma...    train  \n",
       "1  BBB\\n\\nO que gostei: GGG\\n\\nO que não gostei: ...    train  \n",
       "2  Um bom produto por um preço de melhor ainda.\\n...    train  \n",
       "3  Essa camiseta do time esfecifico é muito boa p...    train  \n",
       "4  NÃO TENHO MUiTO O QUE DiZER,AFiNAL COMPREi PAR...    train  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.DataFrame(data=dataset)\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos ler todos os textos e adicionar um novo campo na dataframe que irá ter a sentença sem pontuações e stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEMPO DE EXECUÇÃO: 51.72 segundos\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cons</th>\n",
       "      <th>polarity</th>\n",
       "      <th>pros</th>\n",
       "      <th>review</th>\n",
       "      <th>trainset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>custobenefício durabilidade qualidade material...</td>\n",
       "      <td>3</td>\n",
       "      <td>design</td>\n",
       "      <td>não uniforme palmeiras camisa bonita comprar c...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>qualidade material conforto</td>\n",
       "      <td>3</td>\n",
       "      <td>design custobenefício</td>\n",
       "      <td>bbb gostei ggg não gostei gggg</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>durabilidade qualidade material</td>\n",
       "      <td>3</td>\n",
       "      <td>design custobenefício conforto</td>\n",
       "      <td>bom produto preço melhor ainda gostei bom prod...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>design custobenefício durabilidade qualidade m...</td>\n",
       "      <td>3</td>\n",
       "      <td>não possui nenhum ponto positivo</td>\n",
       "      <td>camiseta time esfecifico é boa causa material ...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>custobenefício</td>\n",
       "      <td>3</td>\n",
       "      <td>não possui nenhum ponto positivo</td>\n",
       "      <td>não dizerafinal comprei presente</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                cons  polarity  \\\n",
       "0  custobenefício durabilidade qualidade material...         3   \n",
       "1                        qualidade material conforto         3   \n",
       "2                    durabilidade qualidade material         3   \n",
       "3  design custobenefício durabilidade qualidade m...         3   \n",
       "4                                     custobenefício         3   \n",
       "\n",
       "                               pros  \\\n",
       "0                            design   \n",
       "1             design custobenefício   \n",
       "2    design custobenefício conforto   \n",
       "3  não possui nenhum ponto positivo   \n",
       "4  não possui nenhum ponto positivo   \n",
       "\n",
       "                                              review trainset  \n",
       "0  não uniforme palmeiras camisa bonita comprar c...    train  \n",
       "1                     bbb gostei ggg não gostei gggg    train  \n",
       "2  bom produto preço melhor ainda gostei bom prod...    train  \n",
       "3  camiseta time esfecifico é boa causa material ...    train  \n",
       "4                   não dizerafinal comprei presente    train  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time.perf_counter()\n",
    "\n",
    "dataframe['review'] = dataframe['review'].apply(preprocessing)\n",
    "dataframe['pros'] = dataframe['pros'].apply(preprocessing)\n",
    "dataframe['cons'] = dataframe['cons'].apply(preprocessing)\n",
    "\n",
    "end_time = time.perf_counter()\n",
    "print('TEMPO DE EXECUÇÃO: {:.2f} segundos'.format(end_time - start_time))\n",
    "\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "train_reviews = dataframe[dataframe['trainset'] == 'train']['review'].values.tolist()\n",
    "train_classes = dataframe[dataframe['trainset'] == 'train']['polarity'].values.tolist()\n",
    "test_reviews = dataframe[dataframe['trainset'] == 'test']['review'].values.tolist()\n",
    "test_classes = dataframe[dataframe['trainset'] == 'test']['polarity'].values.tolist()\n",
    "\n",
    "transformer = TfidfVectorizer()\n",
    "transformer.fit(train_reviews)\n",
    "X = transformer.transform(train_reviews)\n",
    "X_test = transformer.transform(test_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treinando "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bruno/Projetos/.virtualenvs/pln-ven/lib/python3.5/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = SVC()\n",
    "classifier.fit(X, train_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracy_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-193aa255c201>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'accuracy_score' is not defined"
     ]
    }
   ],
   "source": [
    "accuracy_score(test_classes, classifier.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bruno/Projetos/.virtualenvs/pln-ven/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/bruno/Projetos/.virtualenvs/pln-ven/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_lr = LogisticRegression()\n",
    "classifier_lr.fit(X, train_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4388184395046994"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_classes, classifier_lr.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filme é fraco\n",
      "  (0, 21978)\t0.6504526192491843\n",
      "  (0, 21348)\t0.7595468320728326\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3.])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"Esse filme é fraco\"\n",
    "preprocessed_sentence = preprocessing(sentence)\n",
    "print(preprocessed_sentence)\n",
    "instance = transformer.transform([preprocessing(sentence)])\n",
    "print(instance)\n",
    "classifier_lr.predict(instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filme é fraco\n",
      "  (0, 21978)\t0.6504526192491843\n",
      "  (0, 21348)\t0.7595468320728326\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([5.])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"Esse filme é fraco\"\n",
    "preprocessed_sentence = preprocessing(sentence)\n",
    "print(preprocessed_sentence)\n",
    "instance = transformer.transform([preprocessing(sentence)])\n",
    "print(instance)\n",
    "classifier.predict(instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nlputils.semantics.sentiment import Sentiment\n",
    "\n",
    "sentiment = Sentiment()\n",
    "sentiment.sentiment_analysis('Esse filme é bom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
