{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise de Sentimentos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este notebook faz o treinando de machine learning de um modelo de análise de sentimentos, utilizando o dataset do Buscapé fornecido (confidencial), de forma que:\n",
    "- Carrega e estrutura os dados do dataset em dicionário\n",
    "- Exibe estatísticas acerca da do dataset\n",
    "- Apresenta comentários acerca dos resultados obtidos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurações Iniciais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiramente, fazer o ajuste no path do Python para a raíz do projeto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processamento do Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregar a bliblioteca de normalização de texto e de dump de dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlputils.lexical.normalizer import Normalizer\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instanciar um objeto para fazer as normalizações necessárias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = Normalizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementar uma rotina de pré-processamento a ser aplicada em todo o dataset antes de construir o modelo e uma para auxiliar o carregamento dos dados, evitando replicação de código."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função ```preprocessing``` recebe um texto (string) de entrada e o deixa normalizado, conforme procedimentos de nível lexical, e retorna o próprio texto (string) mais compacto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text):\n",
    "    text = normalizer.to_lowercase(text)\n",
    "    text = normalizer.remove_ponctuations(text)\n",
    "    tokens = normalizer.tokenize_words(text)\n",
    "    tokens = normalizer.remove_stopwords(tokens)\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função ```all_files``` recebe o caminho do dataset a ser carregado e gera o caminho de todos os arquivos XML a serem lidos. O caminho de entrada deve terminar com ```/```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_files(dataset_path):\n",
    "    for directory in os.listdir(dataset_path):\n",
    "        if directory != '.DS_Store':\n",
    "            for stars in os.listdir(dataset_path + directory):\n",
    "                for file in os.listdir(dataset_path + directory + '/' + stars):\n",
    "                    if file.endswith('.xml'):\n",
    "                        yield '{}{}/{}/{}'.format(dataset_path, directory, stars, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função ```dumpvar``` salva em dados binário todo o valor de uma variável na memória. Basta fornecer o ponteiro do identificador da variável e o caminho onde será salvo o dump."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dumpvar(var, path):\n",
    "    path_itens = path.split('/')\n",
    "    path_dir = '/'.join(path_itens[:-1]) + '/'\n",
    "    \n",
    "    if not os.path.isdir(path_dir):\n",
    "        os.makedirs(path_dir)\n",
    "    \n",
    "    with open(path, 'wb') as fp:\n",
    "        pickle.dump(var, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função ```loadvar``` retorna o valor de uma dump de memória salvo em disco. Basta o caminho onde está salvo o dump e atribuir em uma variável."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadvar(path):\n",
    "    with open(path, 'rb') as fp:\n",
    "        return pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando o Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importar as bibliotecas utilizadas para fazer o parse do XML e criar a estrutura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xmltodict\n",
    "from xml.parsers.expat import ExpatError\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando os arquivos XML, exibindo estatísticas sobre eles e criando a estrutura que será utilizada no modelo de Machine Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo \"data/trainset/Celular e Smartphone/4.0/2_42055.xml\" está com xml mal formatado\n",
      "Arquivo \"data/trainset/Umidificador/4.0/7_393334.xml\" está com xml mal formatado\n",
      "Arquivo \"data/trainset/Notebook/3.0/0_343109.xml\" está com xml mal formatado\n",
      "Arquivo \"data/trainset/HD/5.0/0_336852.xml\" está com xml mal formatado\n",
      "Arquivo \"data/trainset/Tablet/4.0/0_335616.xml\" está com xml mal formatado\n",
      "-------------------------------------------\n",
      "TEMPO DE EXECUÇÃO: 17.16 segundos\n",
      "Arquivos carregados OK: 67025\n",
      "Arquivos com ERRO: 5\n"
     ]
    }
   ],
   "source": [
    "dataset = {'polarity': [], 'pros': [], 'cons': [], 'review': []}\n",
    "count_ok = 0\n",
    "count_err = 0\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "for file in all_files('data/trainset/'):\n",
    "    filename = file.split('/')[-1]\n",
    "    with open(file, 'r') as text_file:\n",
    "        data = text_file.read()\n",
    "        try:\n",
    "            dict_data = xmltodict.parse(data)\n",
    "            polarity = float(dict_data['review']['stars']['@value'])\n",
    "            dataset['polarity'].append(int(polarity))\n",
    "            dataset['review'].append(str(dict_data['review']['opinion']))\n",
    "            dataset['pros'].append(str(dict_data['review']['pros']))\n",
    "            dataset['cons'].append(str(dict_data['review']['cons']))\n",
    "            count_ok += 1\n",
    "        except ExpatError:\n",
    "            print('Arquivo \"{}\" está com xml mal formatado'.format(file))\n",
    "            count_err += 1\n",
    "\n",
    "end_time = time.perf_counter()\n",
    "\n",
    "print('-------------------------------------------')\n",
    "print('TEMPO DE EXECUÇÃO: {:.2f} segundos'.format(end_time - start_time))\n",
    "print('Arquivos carregados OK:', count_ok)\n",
    "print('Arquivos com ERRO:', count_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estatísticas acerca do dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantidade de comentários:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67025\n"
     ]
    }
   ],
   "source": [
    "print(count_ok)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantidade de sentenças:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantidade de comentários por score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score #0: 671\n",
      "Score #1: 2396\n",
      "Score #2: 2892\n",
      "Score #3: 8936\n",
      "Score #4: 25775\n",
      "Score #5: 26355\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 6):\n",
    "    print('Score #{}: {}'.format(i, dataset['polarity'].count(i)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imporatar biblioteca para aleatorizar a escolha de dados entre treinamento e teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui, o dataset está sendo repartido para criar o conjunto de treinamento e o de teste. Aproximadamente 75% dos dados serão usados para treinamento e 25% para teste. Cada um escolhido entre teste e treino será dado de maneira aleatória."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_test = count_ok // 4\n",
    "size_train = count_ok - size_test\n",
    "\n",
    "dataset['trainset'] = ['train'] * size_train + ['test'] * size_test\n",
    "\n",
    "random.shuffle(dataset['trainset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame(data=dataset)\n",
    "# dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos ler todos os textos e adicionar um novo campo na dataframe que irá ter a sentença sem pontuações e stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEMPO DE EXECUÇÃO: 57.52 segundos\n"
     ]
    }
   ],
   "source": [
    "start_time = time.perf_counter()\n",
    "\n",
    "dataframe['review'] = dataframe['review'].apply(preprocessing)\n",
    "dataframe['pros'] = dataframe['pros'].apply(preprocessing)\n",
    "dataframe['cons'] = dataframe['cons'].apply(preprocessing)\n",
    "\n",
    "end_time = time.perf_counter()\n",
    "print('TEMPO DE EXECUÇÃO: {:.2f} segundos'.format(end_time - start_time))\n",
    "\n",
    "# dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dumpvar(dataframe, 'data/dump/dataframe.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe = loadvar('data/dump/dataframe.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_reviews = dataframe[dataframe['trainset'] == 'train']['review'].values.tolist()\n",
    "train_classes = dataframe[dataframe['trainset'] == 'train']['polarity'].values.tolist()\n",
    "test_reviews = dataframe[dataframe['trainset'] == 'test']['review'].values.tolist()\n",
    "test_classes = dataframe[dataframe['trainset'] == 'test']['polarity'].values.tolist()\n",
    "\n",
    "transformer = TfidfVectorizer()\n",
    "transformer.fit(train_reviews)\n",
    "X = transformer.transform(train_reviews)\n",
    "X_test = transformer.transform(test_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treinando "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEMPO DE EXECUÇÃO: 39.89 segundos\n"
     ]
    }
   ],
   "source": [
    "# classifier = LogisticRegression(solver='warn', multi_class='warn')\n",
    "classifier = LogisticRegression(solver='lbfgs', multi_class='auto', max_iter=200, n_jobs=4)\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "classifier.fit(X, train_classes)\n",
    "end_time = time.perf_counter()\n",
    "print('TEMPO DE EXECUÇÃO: {:.2f} segundos'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5625447600859393"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_classes, classifier.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dumpvar(classifier, 'data/dump/classifier.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier = loadvar('data/dump/classifier.pickle')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
