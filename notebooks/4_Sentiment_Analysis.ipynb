{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise de Sentimentos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treinando a machine learning, utilizando o dataset recebido por email. (Faça o download e coloque a pasta dentro do repositorio)\n",
    "\n",
    "Este notebook faz o treinando de machine learning de um modelo de análise de sentimentos, utilizando o dataset do Buscapé fornecido (confidencial), de forma que:\n",
    "- Carrega e estrutura os dados do dataset em dicionário\n",
    "- Exibe estatísticas acerca da do dataset\n",
    "- Apresenta comentários acerca dos resultados obtidos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurações Iniciais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiramente, fazer o ajuste no path do Python para a raíz do projeto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processamento do Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregar a bliblioteca de normalização de texto e de dump de dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlputils.lexical.normalizer import Normalizer\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instanciar um objeto para fazer as normalizações necessárias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = Normalizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementar uma rotina de pré-processamento a ser aplicada em todo o dataset antes de construir o modelo e uma para auxiliar o carregamento dos dados, evitando replicação de código."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função ```preprocessing``` recebe um texto (string) de entrada e o deixa normalizado, conforme procedimentos de nível lexical, e retorna o próprio texto (string) mais compacto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text):\n",
    "    text = normalizer.to_lowercase(text)\n",
    "    text = normalizer.remove_ponctuations(text)\n",
    "    tokens = normalizer.tokenize_words(text)\n",
    "    tokens = normalizer.remove_stopwords(tokens)\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função ```all_files``` recebe o caminho do dataset a ser carregado e gera o caminho de todos os arquivos XML a serem lidos. O caminho de entrada deve terminal com ```/```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_files(dataset_path):\n",
    "    for directory in os.listdir(dataset_path):\n",
    "        if directory != '.DS_Store':\n",
    "            for stars in os.listdir(dataset_path + directory):\n",
    "                for file in os.listdir(dataset_path + directory + '/' + stars):\n",
    "                    if file.endswith('.xml'):\n",
    "                        yield '{}{}/{}/{}'.format(dataset_path, directory, stars, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função ```dumpvar``` salva em dados binário todo o valor de uma variável na memória. Basta fornecer o ponteiro do identificador da variável e o caminho onde será salvo o dump."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dumpvar(var, path):\n",
    "    path_itens = path.split('/')\n",
    "    path_dir = '/'.join(path_itens[:-1]) + '/'\n",
    "    \n",
    "    if not os.path.isdir(path_dir):\n",
    "        os.makedirs(path_dir)\n",
    "    \n",
    "    with open(path, 'wb') as fp:\n",
    "        pickle.dump(var, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função ```loadvar``` retorna o valor de uma dump de memória salvo em disco. Basta o caminho onde está salvo o dump e atribuir em uma variável."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadvar(path):\n",
    "    with open(path, 'rb') as fp:\n",
    "        pickle.dump(var, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando o Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importar as bibliotecas utilizadas para fazer o parse do XML e criar a estrutura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xmltodict\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando os arquivos XML, exibindo estatísticas sobre eles e criando a estrutura que será utilizada no modelo de Machine Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui, o dataset está sendo repartido ao meio para criar o conjunto de treinamento e o de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo trainset/Tablet/4.0/0_335616.xml está com xml mal formatado\n",
      "Arquivo trainset/Umidificador/4.0/7_393334.xml está com xml mal formatado\n",
      "Arquivo trainset/HD/5.0/0_336852.xml está com xml mal formatado\n",
      "Arquivo trainset/Notebook/3.0/0_343109.xml está com xml mal formatado\n",
      "Arquivo trainset/Celular e Smartphone/4.0/2_42055.xml está com xml mal formatado\n"
     ]
    }
   ],
   "source": [
    "dataset = {'trainset':[], 'polarity':[], 'review':[]}\n",
    "all_files_list = list(all_files('data/trainset/'))\n",
    "partition_size = len(all_files) // 2\n",
    "\n",
    "for idx, file in enumerate(all_files_list):\n",
    "    filename = file.split('/')[-1]\n",
    "    with open(file, 'r') as text_file:\n",
    "        data = text_file.read()\n",
    "        try:\n",
    "            dict_data = xmltodict.parse(data)\n",
    "            dataset['trainset'].append('train') if idx > partition_size else dataset['trainset'].append('test')\n",
    "            polarity = float(dict_data['review']['stars']['@value'])\n",
    "            dataset['polarity'].append(polarity)\n",
    "            dataset['review'].append(str(dict_data['review']['opinion']))\n",
    "        except:\n",
    "            print('Arquivo {} está com xml mal formatado'.format(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trainset</th>\n",
       "      <th>polarity</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>eu amei o violao e eu quero muito avaliar\\n\\nO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>4.0</td>\n",
       "      <td>É um ótimo violão tanto para usar em casa quan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Um produto de excelente, qualidade e leitura</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Um produto de excelente, qualidade e leitura\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Toquei e achei o Maximo, toque e voce tambem v...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  trainset  polarity                                             review\n",
       "0     test       0.0  eu amei o violao e eu quero muito avaliar\\n\\nO...\n",
       "1     test       4.0  É um ótimo violão tanto para usar em casa quan...\n",
       "2     test       4.0       Um produto de excelente, qualidade e leitura\n",
       "3     test       4.0  Um produto de excelente, qualidade e leitura\\n...\n",
       "4     test       4.0  Toquei e achei o Maximo, toque e voce tambem v..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.DataFrame(data=dataset)\n",
    "# dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos ler todos os textos e adicionar um novo campo na dataframe que irá ter a sentença sem pontuações e stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trainset</th>\n",
       "      <th>polarity</th>\n",
       "      <th>review</th>\n",
       "      <th>normalized_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>eu amei o violao e eu quero muito avaliar\\n\\nO...</td>\n",
       "      <td>amei violao quero avaliar gostei cor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>4.0</td>\n",
       "      <td>É um ótimo violão tanto para usar em casa quan...</td>\n",
       "      <td>é ótimo violão tanto usar casa quanto profissi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Um produto de excelente, qualidade e leitura</td>\n",
       "      <td>produto excelente qualidade leitura</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Um produto de excelente, qualidade e leitura\\n...</td>\n",
       "      <td>produto excelente qualidade leitura gostei alg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Toquei e achei o Maximo, toque e voce tambem v...</td>\n",
       "      <td>toquei achei maximo toque voce tambem vai sent...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  trainset  polarity                                             review  \\\n",
       "0     test       0.0  eu amei o violao e eu quero muito avaliar\\n\\nO...   \n",
       "1     test       4.0  É um ótimo violão tanto para usar em casa quan...   \n",
       "2     test       4.0       Um produto de excelente, qualidade e leitura   \n",
       "3     test       4.0  Um produto de excelente, qualidade e leitura\\n...   \n",
       "4     test       4.0  Toquei e achei o Maximo, toque e voce tambem v...   \n",
       "\n",
       "                                   normalized_review  \n",
       "0               amei violao quero avaliar gostei cor  \n",
       "1  é ótimo violão tanto usar casa quanto profissi...  \n",
       "2                produto excelente qualidade leitura  \n",
       "3  produto excelente qualidade leitura gostei alg...  \n",
       "4  toquei achei maximo toque voce tambem vai sent...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe['normalized_review'] = dataframe['review'].apply(preprocessing)\n",
    "# dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "train_reviews = dataframe[dataframe['trainset'] == 'train']['normalized_review'].values.tolist()\n",
    "train_classes = dataframe[dataframe['trainset'] == 'train']['polarity'].values.tolist()\n",
    "test_reviews = dataframe[dataframe['trainset'] == 'test']['normalized_review'].values.tolist()\n",
    "test_classes = dataframe[dataframe['trainset'] == 'test']['polarity'].values.tolist()\n",
    "\n",
    "transformer = TfidfVectorizer()\n",
    "transformer.fit(train_reviews)\n",
    "X = transformer.transform(train_reviews)\n",
    "X_test = transformer.transform(test_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treinando "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bruno/Projetos/.virtualenvs/pln-ven/lib/python3.5/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = SVC()\n",
    "classifier.fit(X, train_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37370211242391693"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_classes, classifier.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bruno/Projetos/.virtualenvs/pln-ven/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/bruno/Projetos/.virtualenvs/pln-ven/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_lr = LogisticRegression()\n",
    "classifier_lr.fit(X, train_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.507906671440506"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_classes, classifier_lr.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filme é fraco\n",
      "  (0, 21978)\t0.6504526192491843\n",
      "  (0, 21348)\t0.7595468320728326\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3.])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"Esse filme é fraco\"\n",
    "preprocessed_sentence = preprocessing(sentence)\n",
    "print(preprocessed_sentence)\n",
    "instance = transformer.transform([preprocessing(sentence)])\n",
    "print(instance)\n",
    "classifier_lr.predict(instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filme é fraco\n",
      "  (0, 21978)\t0.6504526192491843\n",
      "  (0, 21348)\t0.7595468320728326\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([5.])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"Esse filme é fraco\"\n",
    "preprocessed_sentence = preprocessing(sentence)\n",
    "print(preprocessed_sentence)\n",
    "instance = transformer.transform([preprocessing(sentence)])\n",
    "print(instance)\n",
    "classifier.predict(instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
