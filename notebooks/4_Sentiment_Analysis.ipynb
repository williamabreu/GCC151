{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise de Sentimentos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treinando a machine learning, utilizando o dataset recebido por email. (Faça o download e coloque a pasta dentro do repositorio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xmltodict\n",
    "import pandas as pd\n",
    "os.chdir('..')\n",
    "from nlputils.lexical.normalizer import Normalizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pegando todos os arquivos xml do trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'trainset/'\n",
    "all_files = []\n",
    "for directory in os.listdir(dataset_path):\n",
    "    if directory != '.DS_Store':\n",
    "        for stars in os.listdir(dataset_path + directory):\n",
    "            for file in os.listdir(dataset_path + directory + '/' + stars):\n",
    "                if 'xml' in file:\n",
    "                    all_files.append('{}{}/{}/{}'.format(dataset_path, directory, stars, file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando a estrutura que será utilizada pela Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {'trainset':[], 'polarity':[], 'review':[]}\n",
    "for idx, file in enumerate(all_files):\n",
    "    filename = file.split('/')[-1]\n",
    "    with open(file, 'r') as text_file:\n",
    "        data = text_file.read()\n",
    "        try:\n",
    "            dict_data = xmltodict.parse(data)\n",
    "            dataset['trainset'].append('train') if idx > (len(all_files)/2) else dataset['trainset'].append('test')\n",
    "            polarity = float(dict_data['review']['stars']['@value'])\n",
    "            dataset['polarity'].append(polarity)\n",
    "            dataset['review'].append(str(dict_data['review']['opinion']))\n",
    "        except:\n",
    "            print('Arquivo {} está com xml mal formatado'.format(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>review</th>\n",
       "      <th>trainset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Se não fosse o uniforme do palmeiras seria uma...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>BBB\\n\\nO que gostei: GGG\\n\\nO que não gostei: ...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Um bom produto por um preço de melhor ainda.\\n...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Essa camiseta do time esfecifico é muito boa p...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NÃO TENHO MUiTO O QUE DiZER,AFiNAL COMPREi PAR...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   polarity                                             review trainset\n",
       "0       3.0  Se não fosse o uniforme do palmeiras seria uma...     test\n",
       "1       3.0  BBB\\n\\nO que gostei: GGG\\n\\nO que não gostei: ...     test\n",
       "2       3.0  Um bom produto por um preço de melhor ainda.\\n...     test\n",
       "3       3.0  Essa camiseta do time esfecifico é muito boa p...     test\n",
       "4       3.0  NÃO TENHO MUiTO O QUE DiZER,AFiNAL COMPREi PAR...     test"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.DataFrame(data=dataset)\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos ler todos os textos e adicionar um novo campo na dataframe que irá ter a sentença sem pontuações e stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>review</th>\n",
       "      <th>trainset</th>\n",
       "      <th>normalized_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Se não fosse o uniforme do palmeiras seria uma...</td>\n",
       "      <td>test</td>\n",
       "      <td>uniforme palmeiras camisa bonita comprar cores...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>BBB\\n\\nO que gostei: GGG\\n\\nO que não gostei: ...</td>\n",
       "      <td>test</td>\n",
       "      <td>bbb gostei ggg gostei gggg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Um bom produto por um preço de melhor ainda.\\n...</td>\n",
       "      <td>test</td>\n",
       "      <td>bom produto preço melhor ainda gostei bom prod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Essa camiseta do time esfecifico é muito boa p...</td>\n",
       "      <td>test</td>\n",
       "      <td>camiseta time esfecifico é boa causa material ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NÃO TENHO MUiTO O QUE DiZER,AFiNAL COMPREi PAR...</td>\n",
       "      <td>test</td>\n",
       "      <td>dizerafinal comprei presente</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   polarity                                             review trainset  \\\n",
       "0       3.0  Se não fosse o uniforme do palmeiras seria uma...     test   \n",
       "1       3.0  BBB\\n\\nO que gostei: GGG\\n\\nO que não gostei: ...     test   \n",
       "2       3.0  Um bom produto por um preço de melhor ainda.\\n...     test   \n",
       "3       3.0  Essa camiseta do time esfecifico é muito boa p...     test   \n",
       "4       3.0  NÃO TENHO MUiTO O QUE DiZER,AFiNAL COMPREi PAR...     test   \n",
       "\n",
       "                                   normalized_review  \n",
       "0  uniforme palmeiras camisa bonita comprar cores...  \n",
       "1                         bbb gostei ggg gostei gggg  \n",
       "2  bom produto preço melhor ainda gostei bom prod...  \n",
       "3  camiseta time esfecifico é boa causa material ...  \n",
       "4                       dizerafinal comprei presente  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "normalizer = Normalizer()\n",
    "\n",
    "def preprocessing(text):\n",
    "    text = normalizer.to_lowercase(text)\n",
    "    text = normalizer.remove_ponctuations(text)\n",
    "    tokens = normalizer.tokenize_words(text)\n",
    "    tokens = normalizer.remove_stopwords(tokens)\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "dataframe['normalized_review'] = dataframe['review'].apply(preprocessing)\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "train_reviews = dataframe[dataframe['trainset'] == 'train']['normalized_review'].values.tolist()\n",
    "train_classes = dataframe[dataframe['trainset'] == 'train']['polarity'].values.tolist()\n",
    "test_reviews = dataframe[dataframe['trainset'] == 'test']['normalized_review'].values.tolist()\n",
    "test_classes = dataframe[dataframe['trainset'] == 'test']['polarity'].values.tolist()\n",
    "\n",
    "transformer = TfidfVectorizer()\n",
    "transformer.fit(train_reviews)\n",
    "X = transformer.transform(train_reviews)\n",
    "X_test = transformer.transform(test_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treinando "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bruno/Projetos/.virtualenvs/pln-ven/lib/python3.5/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = SVC()\n",
    "classifier.fit(X, train_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37370211242391693"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_classes, classifier.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bruno/Projetos/.virtualenvs/pln-ven/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/bruno/Projetos/.virtualenvs/pln-ven/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_lr = LogisticRegression()\n",
    "classifier_lr.fit(X, train_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.507906671440506"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_classes, classifier_lr.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filme é fraco\n",
      "  (0, 21978)\t0.6504526192491843\n",
      "  (0, 21348)\t0.7595468320728326\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3.])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"Esse filme é fraco\"\n",
    "preprocessed_sentence = preprocessing(sentence)\n",
    "print(preprocessed_sentence)\n",
    "instance = transformer.transform([preprocessing(sentence)])\n",
    "print(instance)\n",
    "classifier_lr.predict(instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filme é fraco\n",
      "  (0, 21978)\t0.6504526192491843\n",
      "  (0, 21348)\t0.7595468320728326\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([5.])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"Esse filme é fraco\"\n",
    "preprocessed_sentence = preprocessing(sentence)\n",
    "print(preprocessed_sentence)\n",
    "instance = transformer.transform([preprocessing(sentence)])\n",
    "print(instance)\n",
    "classifier.predict(instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
